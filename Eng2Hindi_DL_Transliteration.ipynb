{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Eng2Hindi - DL Transliteration.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "IOI4rlrgxPI-",
        "eYrAa5laSptM",
        "M9iH3ZvyOeNa",
        "SSw1SMZmx9A3",
        "Ob3F9Dh4PChB",
        "7l-iaCVdx5Ez"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOI4rlrgxPI-",
        "colab_type": "text"
      },
      "source": [
        "## Setting up the dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GqTjeV47m4B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "# Instantiates the device to be used as GPU/CPU based on availability\n",
        "device_gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Visualization tools\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpuvHS0mxwCd",
        "colab_type": "text"
      },
      "source": [
        "## Data Management"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYrAa5laSptM",
        "colab_type": "text"
      },
      "source": [
        "### Alphabets Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-a04ZKx7Sh-J",
        "colab_type": "code",
        "outputId": "8c42bbc0-3890-4b86-f1c8-d4879e47afe2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "eng_alphabets = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "pad_char = '-PAD-'\n",
        "\n",
        "eng_alpha2index = {pad_char: 0}\n",
        "for index, alpha in enumerate(eng_alphabets):\n",
        "    eng_alpha2index[alpha] = index+1\n",
        "\n",
        "print(eng_alpha2index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10, 'K': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15, 'P': 16, 'Q': 17, 'R': 18, 'S': 19, 'T': 20, 'U': 21, 'V': 22, 'W': 23, 'X': 24, 'Y': 25, 'Z': 26}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPSZsy1kXd9w",
        "colab_type": "code",
        "outputId": "474a43f1-3617-4aed-aec5-fc758ad41b1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Hindi Unicode Hex Range: https://en.wikipedia.org/wiki/Devanagari_(Unicode_block)\n",
        "hindi_alphabets = [chr(alpha) for alpha in range(2304, 2432)]\n",
        "hindi_alphabet_size = len(hindi_alphabets)\n",
        "\n",
        "hindi_alpha2index = {pad_char: 0}\n",
        "for index, alpha in enumerate(hindi_alphabets):\n",
        "    hindi_alpha2index[alpha] = index+1\n",
        "\n",
        "print(hindi_alpha2index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9iH3ZvyOeNa",
        "colab_type": "text"
      },
      "source": [
        "### Downloading the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSw1SMZmx9A3",
        "colab_type": "text"
      },
      "source": [
        "### Helper functions for data pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcS6ByndOxrC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "non_eng_letters_regex = re.compile('[^a-zA-Z ]')\n",
        "\n",
        "# Returns a list of English words in the given line,\n",
        "# containing only upper-case letters\n",
        "def cleanEnglishVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ').upper()\n",
        "    # Remove all non-letters\n",
        "    line = non_eng_letters_regex.sub('', line)\n",
        "    return line.split()\n",
        "\n",
        "# Returns a list of Hindi words in the given line,\n",
        "# containing only Hindi characters\n",
        "def cleanHindiVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ')\n",
        "    # Remove all non-Hindi chars except space\n",
        "    cleaned_line = ''\n",
        "    for char in line:\n",
        "        if char in hindi_alpha2index or char == ' ':\n",
        "            cleaned_line += char\n",
        "    \n",
        "    return cleaned_line.split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob3F9Dh4PChB",
        "colab_type": "text"
      },
      "source": [
        "### Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGSeoMGg0FTy",
        "colab_type": "code",
        "outputId": "e0fb18cd-e3ec-4057-e2e8-7a5f907f01fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "class TransliterationDataLoader(Dataset):\n",
        "    def __init__(self, filename):\n",
        "        self.eng_words, self.hindi_words = self.readXmlDataset(filename, cleanHindiVocab)\n",
        "        self.shuffle_indices = list(range(len(self.eng_words)))\n",
        "        random.shuffle(self.shuffle_indices)\n",
        "        self.shuffle_start_index = 0\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.eng_words)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.eng_words[idx], self.hindi_words[idx]\n",
        "    \n",
        "    def readXmlDataset(self, filename, lang_vocab_cleaner):\n",
        "        transliterationCorpus = ET.parse(filename).getroot()\n",
        "        lang1_words = []\n",
        "        lang2_words = []\n",
        "\n",
        "        for line in transliterationCorpus:\n",
        "            wordlist1 = cleanEnglishVocab(line[0].text)\n",
        "            wordlist2 = lang_vocab_cleaner(line[1].text)\n",
        "\n",
        "            # Skip noisy data\n",
        "            if len(wordlist1) != len(wordlist2):\n",
        "                print('Skipping: ', line[0].text, ' - ', line[1].text)\n",
        "                continue\n",
        "\n",
        "            for word in wordlist1:\n",
        "                lang1_words.append(word)\n",
        "            for word in wordlist2:\n",
        "                lang2_words.append(word)\n",
        "\n",
        "        return lang1_words, lang2_words\n",
        "    \n",
        "    def get_random_sample(self):\n",
        "        return self.__getitem__(np.random.randint(len(self.eng_words)))\n",
        "    \n",
        "    def get_batch_from_array(self, batch_size, array):\n",
        "        end = self.shuffle_start_index + batch_size\n",
        "        batch = []\n",
        "        if end >= len(self.eng_words):\n",
        "            batch = [array[i] for i in self.shuffle_indices[0:end%len(self.eng_words)]]\n",
        "            end = len(self.eng_words)\n",
        "        return batch + [array[i] for i in self.shuffle_indices[self.shuffle_start_index : end]]\n",
        "    \n",
        "    def get_batch(self, batch_size, postprocess = True):\n",
        "        eng_batch = self.get_batch_from_array(batch_size, self.eng_words)\n",
        "        hindi_batch = self.get_batch_from_array(batch_size, self.hindi_words)\n",
        "        self.shuffle_start_index += batch_size + 1\n",
        "        \n",
        "        # Reshuffle if 1 epoch is complete\n",
        "        if self.shuffle_start_index >= len(self.eng_words):\n",
        "            random.shuffle(self.shuffle_indices)\n",
        "            self.shuffle_start_index = 0\n",
        "            \n",
        "        return eng_batch, hindi_batch\n",
        "    \n",
        "train_data = TransliterationDataLoader('NEWS2012-Training-EnHi-13937.xml')\n",
        "test_data = TransliterationDataLoader('NEWS2012-Ref-EnHi-1000.xml')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Skipping:  BARHARWA JUNCTION  -  बरहरवा\n",
            "Skipping:  STATE BNK TR  -  स्टेट बैंक ऑफ त्रावणकोर\n",
            "Skipping:  SOUTH ARLINGTON CHURCH OF CHRIST  -  साउथ अर्लिंग्टन\n",
            "Skipping:  KING EDWARD VII  -  किंग एडवर्ड\n",
            "Skipping:  DIBANG VALLEY  -  दिबंगवैली\n",
            "Skipping:  ORDER OF VASA  -  ऑडर ऑफ़ द वासा\n",
            "Skipping:  AZAMNAGAR ROAD  -  आज़मनगर\n",
            "Skipping:  CAPE TOWN  -  केपटाउन\n",
            "Skipping:  NEW ZEALAND  -  न्यूज़ीलैंड\n",
            "Skipping:  SEA OF THE HEBRIDES  -  सी ऑफ हरब्रिड्‍स\n",
            "Skipping:  RAMCOIND  -  राम्को इंड\n",
            "Skipping:  KELVINGROVE ART GALLERY AND MUSEUM  -  केल्व‍िनग्रोव आर्ट एण्ड म्युज़ियम\n",
            "Skipping:  AUSTRALIAN NATIONAL UNIVERSITY  -  ऑस्ट्रेलियननेशनल यूनिवर्सिटी\n",
            "Skipping:  JAHAN AARA  -  जहाँआरा\n",
            "Skipping:  NAVABHARAT FERRO ALLOYS  -  नव भारत फ़ैरो अलॉय\n",
            "Skipping:  RAMA LINGESHWARA  -  रामालिंगेश्वर\n",
            "Skipping:  FAKHRUN NISA  -  फखरुन्निसा\n",
            "Skipping:  REDIFF.COM INDIA LIMITED  -  रेडिफ़ डॉट कॉम इंडिया लिमिटेड\n",
            "Skipping:  OMKARNATH THAKUR  -  ओंकार नाथ ठाकुर\n",
            "Skipping:  OPENTV  -  ओपन टीवी\n",
            "Skipping:  ENVOY COMMUNICATIONS GROUP  -  एन्वॉय कम्युनिकेशंस\n",
            "Skipping:  WAR OF THE HOLY LEAGUE  -  वार ऑफ होली लीग\n",
            "Skipping:  VAPARAISO CHURCH OF CHRIST  -  व्हापरासिओ\n",
            "Skipping:  PARIS CHARLES DE GAULLE  -  पेरिस रॉसे चार्ल्स डे ग्यूले\n",
            "Skipping:  PARKWAY APOSTOLIC  -  पार्क वे अपोस्टोलिक\n",
            "Skipping:  MAUNA LOA  -  मौनालोआ\n",
            "Skipping:  MASS MUTUAL LIFE  -  मास म्युच्युअल लाइफ़ इंश्योरेंस\n",
            "Skipping:  STATS CHIPPAC  -  स्टेट्सचिपपैक\n",
            "Skipping:  NEWFOUNDLAND  -  न्यू फाउंडलैंड\n",
            "Skipping:  LONDONHEATHROW  -  लंदन हीथ्रो\n",
            "Skipping:  RETALIX  -  रेटालिक्स लि.\n",
            "Skipping:  SRISAILAM  -  श्री शैलम\n",
            "Skipping:  KARA-KUM  -  काराकुम\n",
            "Skipping:  WIND RIVER  -  विंडरिवर\n",
            "Skipping:  NETAJI SUBHASH CHANDRA BOSE  -  नेताजी सुभाषचंद्र बोस\n",
            "Skipping:  ROCKBROOK UNITED  -  रॉकब्रुक यूनाइटेड मेथोडिस्ट\n",
            "Skipping:  WALTER SCOTT  -  वॉल्टरस्कॉट\n",
            "Skipping:  COLOURPLUS FASHIONS  -  कलर प्लस फ़ैशन्स\n",
            "Skipping:  BAL KRISHNA  -  बालकृष्णा\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7l-iaCVdx5Ez",
        "colab_type": "text"
      },
      "source": [
        "### Basic Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjY06ghEx76b",
        "colab_type": "code",
        "outputId": "00a65f73-ea9d-4842-bf0e-e56d3f421119",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "print(\"Train Set Size:\\t\", len(train_data))\n",
        "print(\"Test Set Size:\\t\", len(test_data))\n",
        "\n",
        "print('\\nSample data from train-set:')\n",
        "for i in range(10):\n",
        "    eng, hindi = train_data.get_random_sample()\n",
        "    print(eng + ' - ' + hindi)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Set Size:\t 20543\n",
            "Test Set Size:\t 1000\n",
            "\n",
            "Sample data from train-set:\n",
            "JAI - जय\n",
            "CHIP - चिप\n",
            "BRIAN - ब्रायन\n",
            "CARESSE - कैरेसी\n",
            "FRANKLIN - फ्रेंकलिन\n",
            "VIMICRO - विमाइक्रो\n",
            "BARODA - बड़ौदा\n",
            "OCARINA - ऑकारिना\n",
            "INDO - इंडो\n",
            "SYED - सय्यद\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpDP1_KYZIkv",
        "colab_type": "text"
      },
      "source": [
        "### Encoding the words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE3at5C7Sy5F",
        "colab_type": "code",
        "outputId": "eae00864-fd69-4542-9ac6-828f868d5fc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "def word_rep(word, letter2index, device = 'cpu'):\n",
        "    rep = torch.zeros(len(word)+1, 1, len(letter2index)).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        rep[letter_index][0][pos] = 1\n",
        "    pad_pos = letter2index[pad_char]\n",
        "    rep[letter_index+1][0][pad_pos] = 1\n",
        "    return rep\n",
        "\n",
        "def gt_rep(word, letter2index, device = 'cpu'):\n",
        "    gt_rep = torch.zeros([len(word)+1, 1], dtype=torch.long).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        gt_rep[letter_index][0] = pos\n",
        "    gt_rep[letter_index+1][0] = letter2index[pad_char]\n",
        "    return gt_rep\n",
        "\n",
        "eng, hindi = train_data.get_random_sample()\n",
        "eng_rep = word_rep(eng, eng_alpha2index)\n",
        "print(eng, eng_rep)\n",
        "\n",
        "hindi_gt = gt_rep(hindi, hindi_alpha2index)\n",
        "print(hindi, hindi_gt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "HAI tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n",
            "है tensor([[58],\n",
            "        [73],\n",
            "        [ 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrC3tSnm4rUk",
        "colab_type": "text"
      },
      "source": [
        "## Network Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4OgdZ_DVVC5",
        "colab_type": "text"
      },
      "source": [
        "### Encoder-Decoder (using GRU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6w8ffT3w4lkK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_OUTPUT_CHARS = 30\n",
        "class Transliteration_EncoderDecoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(Transliteration_EncoderDecoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n",
        "        self.decoder_rnn_cell = nn.GRU(output_size, hidden_size)\n",
        "        self.h2o = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=2)\n",
        "        \n",
        "    def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
        "        out, hidden = self.encoder_rnn_cell(input)\n",
        "        decoder_state = hidden\n",
        "        decoder_input = torch.zeros(1, 1, self.output_size).to(device)\n",
        "        outputs = []\n",
        "        for i in range(max_output_chars):\n",
        "            out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
        "            out = self.h2o(decoder_state)\n",
        "            out = self.softmax(out)\n",
        "            outputs.append(out.view(1, -1))\n",
        "            # Get OHE from Softmax: https://discuss.pytorch.org/t/softmax-to-one-hot/37302\n",
        "            max_idx = torch.argmax(out, 2, keepdim=True)\n",
        "            if not ground_truth is None:\n",
        "                max_idx = ground_truth[i].reshape(1, 1, 1)\n",
        "            one_hot = torch.FloatTensor(out.shape).to(device)\n",
        "            one_hot.zero_()\n",
        "            one_hot.scatter_(2, max_idx, 1)\n",
        "            decoder_input = one_hot.detach()\n",
        "            \n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzM74zGtVbGB",
        "colab_type": "text"
      },
      "source": [
        "### Encoder-Decoder with Attention (Type 1)\n",
        "(mechanism based on [PyTorch Docs](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NRMybNU7rzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_ENCODER_STEPS = 30\n",
        "\n",
        "class Transliteration_EncoderDecoderAttention(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, max_encoder_steps = MAX_ENCODER_STEPS):\n",
        "        super(Transliteration_EncoderDecoderAttention, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n",
        "        self.decoder_rnn_cell = nn.GRU(hidden_size, hidden_size)\n",
        "        self.h2o = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=2)\n",
        "        \n",
        "        self.max_encoder_steps = max_encoder_steps\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, max_encoder_steps)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.out2hidden = nn.Linear(self.output_size, self.hidden_size)\n",
        "        \n",
        "        \n",
        "    def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
        "        out, hidden = self.encoder_rnn_cell(input)\n",
        "        decoder_state = hidden\n",
        "        \n",
        "        encoder_outputs = torch.zeros(self.max_encoder_steps, self.hidden_size, device=device)\n",
        "        for i in range(out.shape[0]):\n",
        "            encoder_outputs[i] = out[i, 0]\n",
        "        \n",
        "        decoder_input = torch.zeros(1, 1, self.output_size).to(device)\n",
        "        outputs = []\n",
        "        for i in range(max_output_chars):\n",
        "            embedding = self.out2hidden(decoder_input)\n",
        "            attn_weights = F.softmax(\n",
        "                self.attn(torch.cat((embedding[0], decoder_state[0]), 1)), dim=1)\n",
        "            attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "            decoder_input = torch.cat((embedding[0], attn_applied[0]), 1)\n",
        "            decoder_input = self.attn_combine(decoder_input).unsqueeze(0)\n",
        "            decoder_input = F.relu(decoder_input)\n",
        "            \n",
        "            \n",
        "            out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
        "            out = self.h2o(decoder_state)\n",
        "            out = self.softmax(out)\n",
        "            outputs.append(out.view(1, -1))\n",
        "            # Get OHE from Softmax: https://discuss.pytorch.org/t/softmax-to-one-hot/37302\n",
        "            max_idx = torch.argmax(out, 2, keepdim=True)\n",
        "            if not ground_truth is None:\n",
        "                max_idx = ground_truth[i].reshape(1, 1, 1)\n",
        "            one_hot = torch.zeros(out.shape, device = device)\n",
        "            one_hot.scatter_(2, max_idx, 1)\n",
        "            decoder_input = one_hot.detach()\n",
        "            \n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEg49N9e7oTY",
        "colab_type": "text"
      },
      "source": [
        "### Encoder-Decoder with Attention (Type 2)\n",
        "(mechanism based on [Mitesh's lectures on Attention](https://www.cse.iitm.ac.in/~miteshk/CS7015_2018.html))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z-1QDAz8F_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Transliteration_EncoderDecoderAttention_Type2(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(Transliteration_EncoderDecoderAttention_Type2, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n",
        "        self.decoder_rnn_cell = nn.GRU(hidden_size*2, hidden_size)\n",
        "        self.h2o = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=2)\n",
        "        \n",
        "        self.U = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.W = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size, 1)\n",
        "        self.out2hidden = nn.Linear(self.output_size, self.hidden_size)\n",
        "        \n",
        "        \n",
        "    def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
        "        encoder_outputs, hidden = self.encoder_rnn_cell(input)\n",
        "        encoder_outputs = encoder_outputs.view(-1, self.hidden_size)\n",
        "        decoder_state = hidden\n",
        "        \n",
        "        decoder_input = torch.zeros(1, 1, self.output_size).to(device)\n",
        "        outputs = []\n",
        "        U = self.U(encoder_outputs)\n",
        "        \n",
        "        for i in range(max_output_chars):\n",
        "            W = self.W(decoder_state.view(1, -1).repeat(encoder_outputs.shape[0], 1))\n",
        "            V = self.attn(torch.tanh(U + W))\n",
        "            attn_weights = F.softmax(V.view(1, -1), dim = 1)\n",
        "            \n",
        "            attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "            embedding = self.out2hidden(decoder_input)\n",
        "            decoder_input = torch.cat((embedding[0], attn_applied[0]), 1).unsqueeze(0)\n",
        "            \n",
        "            out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
        "            out = self.h2o(decoder_state)\n",
        "            out = self.softmax(out)\n",
        "            outputs.append(out.view(1, -1))\n",
        "            # Get OHE from Softmax: https://discuss.pytorch.org/t/softmax-to-one-hot/37302\n",
        "            max_idx = torch.argmax(out, 2, keepdim=True)\n",
        "            if not ground_truth is None:\n",
        "                max_idx = ground_truth[i].reshape(1, 1, 1)\n",
        "            one_hot = torch.zeros(out.shape, device=device)\n",
        "            one_hot.scatter_(2, max_idx, 1) # In dim 2, set max_idx's as 1\n",
        "            decoder_input = one_hot.detach()\n",
        "            \n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyE2tSnmAW6x",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H893cimDtTUE",
        "colab_type": "text"
      },
      "source": [
        "### Core Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m804jsH7AXSV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_batch(net, opt, criterion, batch_size, device = 'cpu', teacher_force = False):\n",
        "    net.train().to(device)\n",
        "    opt.zero_grad()\n",
        "    eng_batch, hindi_batch = train_data.get_batch(batch_size)\n",
        "    \n",
        "    total_loss = 0\n",
        "    for i in range(batch_size):\n",
        "        input = word_rep(eng_batch[i], eng_alpha2index, device)\n",
        "        gt = gt_rep(hindi_batch[i], hindi_alpha2index, device)\n",
        "        outputs = net(input, gt.shape[0], device, ground_truth = gt if teacher_force else None)\n",
        "        \n",
        "        for index, output in enumerate(outputs):\n",
        "            loss = criterion(output, gt[index]) / batch_size\n",
        "            loss.backward(retain_graph = True)\n",
        "            total_loss += loss\n",
        "        \n",
        "    opt.step()\n",
        "    return total_loss/batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-eZaBxstWz9",
        "colab_type": "text"
      },
      "source": [
        "### Training Helper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rjto129ssrpr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_setup(net, lr = 0.01, n_batches = 100, batch_size = 10, momentum = 0.9, display_freq=5, device = 'cpu'):\n",
        "    net = net.to(device)\n",
        "    criterion = nn.NLLLoss(ignore_index = -1)\n",
        "    opt = optim.Adam(net.parameters(), lr=lr)\n",
        "    teacher_force_upto = n_batches//3\n",
        "    \n",
        "    loss_arr = np.zeros(n_batches + 1)\n",
        "    \n",
        "    for i in range(n_batches):\n",
        "        loss_arr[i+1] = (loss_arr[i]*i + train_batch(net, opt, criterion, batch_size, device = device, teacher_force = i<teacher_force_upto ))/(i + 1)\n",
        "        \n",
        "        if i%display_freq == display_freq-1:\n",
        "            clear_output(wait=True)\n",
        "            \n",
        "            print('Iteration', i, 'Loss', loss_arr[i])\n",
        "            # print('Top-1:', eval(net, len(X_test), 1, X_test, y_test), 'Top-2:', eval(net, len(X_test), 2, X_test, y_test))\n",
        "            plt.figure()\n",
        "            plt.plot(loss_arr[1:i], '-*')\n",
        "            plt.xlabel('Iteration')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.show()\n",
        "            print('\\n\\n')\n",
        "            \n",
        "    #print('Top-1:', eval(net, len(X_test), 1, X_test, y_test, device), 'Top-2:', eval(net, len(X_test), 2, X_test, y_test, device))\n",
        "    torch.save(net, 'model.pt')\n",
        "    return loss_arr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZY6RvqLtdX8",
        "colab_type": "text"
      },
      "source": [
        "### Training without Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oQ3ZIWvtjfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = Transliteration_EncoderDecoder(len(eng_alpha2index), 256, len(hindi_alpha2index))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6LjVKQfoVMU",
        "colab_type": "code",
        "outputId": "f79e9eae-393e-48d8-b117-075fdc7b185a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        }
      },
      "source": [
        "train_setup(net, lr=0.001, n_batches=2000, batch_size = 64, display_freq=10, device = device_gpu)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1999 Loss 0.014933338388800621\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Transliteration_EncoderDecoder. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.03358546, 0.03683273, ..., 0.0149389 , 0.01493334,\n",
              "       0.01492873])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWQss1PvmmJw",
        "colab_type": "text"
      },
      "source": [
        "### Training with Attention Type 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJOGewYJY_yR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net2 = Transliteration_EncoderDecoderAttention(len(eng_alpha2index), 256, len(hindi_alpha2index))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AKEEGp1ZOKK",
        "colab_type": "code",
        "outputId": "15639d3a-9cc4-457b-a0ce-2602a5bfa050",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "loss_history = train_setup(net2, lr=0.001, n_batches=20000, batch_size = 64, display_freq=10, device = device_gpu)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 12779 Loss 0.030761290341615677\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-edfcd056a67e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-5f97d45260cc>\u001b[0m in \u001b[0;36mtrain_setup\u001b[0;34m(net, lr, n_batches, batch_size, momentum, display_freq, device)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mloss_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mdisplay_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdisplay_freq\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-a92206183b20>\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(net, opt, criterion, batch_size, device)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1869\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   1870\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1871\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1872\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1873\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM1Tj20omMi1",
        "colab_type": "text"
      },
      "source": [
        "### Training with Attention Type 2 (Mitesh)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxFLBqW1Ip4v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net3 = Transliteration_EncoderDecoderAttention_Type2(len(eng_alpha2index), 256, len(hindi_alpha2index))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdRpJUXNIwuv",
        "colab_type": "code",
        "outputId": "6ced8c1c-ed2c-48f3-cc79-2235af5171bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        }
      },
      "source": [
        "loss_history = train_setup(net3, lr=0.001, n_batches=20000, batch_size = 64, display_freq=10, device = device_gpu)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 10579 Loss 0.04278186336159706\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05F1-FwX6YVZ",
        "colab_type": "text"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bT8bibYl7CgX",
        "colab_type": "code",
        "outputId": "d99f252b-beb5-4390-a2f4-927751e6166d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def infer(net, word, char_limit, device = 'cpu'):\n",
        "    input = word_rep(word, eng_alpha2index, device)\n",
        "    return net(input, char_limit)\n",
        "\n",
        "def test(net, word, device = 'cpu'):\n",
        "    net = net.eval().to(device)\n",
        "    outputs = infer(net, word, 30, device)\n",
        "    hindi_output = ''\n",
        "    for out in outputs:\n",
        "        val, indices = out.topk(1)\n",
        "        index = indices.tolist()[0][0]\n",
        "        if index == 0:\n",
        "            break\n",
        "        hindi_char = hindi_alphabets[index+1]\n",
        "        hindi_output += hindi_char\n",
        "    print(word + ' - ' + hindi_output)\n",
        "    return hindi_output\n",
        "\n",
        "def calc_accuracy(net, device = 'cpu'):\n",
        "    net = net.eval().to(device)\n",
        "    predictions = []\n",
        "    accuracy = 0\n",
        "    for i in range(len(test_data)):\n",
        "        eng, hindi = test_data[i]\n",
        "        gt = gt_rep(hindi, hindi_alpha2index, device)\n",
        "        outputs = infer(net, eng, gt.shape[0], device)\n",
        "        correct = 0\n",
        "        for index, out in enumerate(outputs):\n",
        "            val, indices = out.topk(1)\n",
        "            hindi_pos = indices.tolist()[0]\n",
        "            if hindi_pos[0] == gt[index][0]:\n",
        "                correct += 1\n",
        "        \n",
        "        accuracy += correct/gt.shape[0]\n",
        "    accuracy /= len(test_data)\n",
        "    return accuracy\n",
        "\n",
        "# hindi_word = test(net2, 'HELLO')\n",
        "\n",
        "accuracy = calc_accuracy(net2) * 100\n",
        "print('Accuracy: ', accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  81.23\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}